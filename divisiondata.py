# -*- coding: utf-8 -*-
"""DivisionData.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19oZhert6oGcw9l2yVRJxHW4Y12B-BYuw
"""

import requests
import pandas as pd

divisions = pd.read_csv("unions.csv",names=["divid","id","eng","bang","web"])

divisions.head()

del divisions['eng']
del divisions['divid']
del divisions['web']

for i,row in divisions.iterrows():
    url2015   = "http://dev.pipilika.com:5001/get_dengue_news?location="+row['bang']+"&start_date=2015-01-01&end_date=2015-12-31"
    request2015  = requests.get(url2015).json()
    divisions.loc[i,'2015']  = request2015
    url2016   = "http://dev.pipilika.com:5001/get_dengue_news?location="+row['bang']+"&start_date=2016-01-01&end_date=2016-12-31"
    request2016  = requests.get(url2016).json()
    divisions.loc[i,'2016']  = request2016
    url2017   = "http://dev.pipilika.com:5001/get_dengue_news?location="+row['bang']+"&start_date=2017-01-01&end_date=2017-12-31"
    request2017 = requests.get(url2017).json()
    divisions.loc[i,'2017']  = request2017
    url2018   = "http://dev.pipilika.com:5001/get_dengue_news?location="+row['bang']+"&start_date=2018-01-01&end_date=2018-12-31"
    request2018  = requests.get(url2018).json()
    divisions.loc[i,'2018']  = request2018
    url2019   = "http://dev.pipilika.com:5001/get_dengue_news?location="+row['bang']+"&start_date=2019-01-01&end_date=2019-12-31"
    request2019  = requests.get(url2019).json()
    divisions.loc[i,'2019']  = request2019
    url2020 = "http://dev.pipilika.com:5001/get_dengue_news?location="+row['bang']+"&start_date=2020-01-01&end_date=2020-03-31"
    request2020 = requests.get(url2020).json()
    divisions.loc[i,'2020'] = request2020
    print(i)

divisions.to_csv("unionData.csv")

